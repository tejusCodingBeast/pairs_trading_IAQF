{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f2ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from hurst import compute_Hc\n",
    "import statsmodels.tsa.stattools as ts\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import scipy.optimize as spop\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statistics import mean\n",
    "from statsmodels.tsa.stattools import coint\n",
    "import json\n",
    "from numpy import cumsum, log, polyfit, sqrt, std\n",
    "from numpy.random import randn\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517dc6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "sns.set_style('darkgrid')\n",
    "prices = pd.read_csv('etfs.csv')\n",
    "#prices.columns\n",
    "prices['Date'] = pd.to_datetime(prices['Date'])\n",
    "prices = prices.set_index('Date')\n",
    "prices = prices.dropna(axis=1)\n",
    "prices.head()\n",
    "returns = np.log(prices).diff().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed76d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_VALUE_THRESHOLD = 0.05\n",
    "HURST_THRESHOLD = 0.5\n",
    "TRADING_PERIOD = 253"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9fb7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "form_start = '2011-01-01'\n",
    "form_end = '2016-12-31'\n",
    "trade_start = '2017-01-01'\n",
    "trade_end = '2019-12-31'\n",
    "\n",
    "prices_form = prices[form_start:form_end]\n",
    "prices_trade = prices[trade_start:trade_end]\n",
    "returns_form = returns.loc[form_start:form_end]\n",
    "returns_trade = returns.loc[trade_start:trade_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2641bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engle_granger_cointegration_test(X, Y):\n",
    "    # Calculate the cointegration test statistics and p-value using the coint() function\n",
    "    _, pvalue, _ = coint(X, Y)\n",
    "    return pvalue\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcf56fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hurst(X):\n",
    "    \"\"\"Returns the Hurst Exponent of the time series vector X\"\"\"\n",
    "    # Create the range of lag values\n",
    "    lags = range(2, 100)\n",
    "    # Calculate the array of the variances of the lagged differences\n",
    "    tau = [np.sqrt(np.std(np.subtract(X[lag:], X[:-lag]))) for lag in lags]\n",
    "    # Use polyfit to estimate the Hurst exponent\n",
    "    poly = np.polyfit(np.log(lags), np.log(tau), 1)\n",
    "    return poly[0]*2.0\n",
    "\n",
    "def calculate_hurst_of_spread(X, Y):\n",
    "    # Calculate the spread between X and Y\n",
    "    spread = X - Y\n",
    "\n",
    "    # Check if spread has any zeroes or NaNs\n",
    "    if np.any(np.isnan(spread)) or np.any(spread == 0):\n",
    "        return np.nan\n",
    "\n",
    "    # Calculate the Hurst exponent of the spread\n",
    "    hurst_exp = hurst(spread)\n",
    "\n",
    "    return hurst_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0824dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_crosses(X, Y):\n",
    "    spread = X - Y\n",
    "    mean_spread = np.mean(spread)\n",
    "    cross_count = 0\n",
    "    for i in range(len(spread)-1):\n",
    "        if (spread[i] - mean_spread) * (spread[i+1] - mean_spread) < 0:\n",
    "            cross_count += 1\n",
    "    return cross_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9754b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def calculate_half_life(X, Y):\n",
    "    spread = X - Y\n",
    "\n",
    "    delta_spread = np.diff(spread)\n",
    "\n",
    "    lagged_spread = spread[:-1]\n",
    "\n",
    "    lagged_spread_with_constant = np.column_stack((lagged_spread, np.ones_like(lagged_spread)))\n",
    "\n",
    "    coeffs = np.linalg.lstsq(lagged_spread_with_constant, delta_spread, rcond=None)[0]\n",
    "\n",
    "    half_life = -np.log(2) / coeffs[0]\n",
    "\n",
    "    return half_life\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613a6bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correlation(time_series1, time_series2):\n",
    "    return stats.pearsonr(time_series1, time_series2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd20d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The null hypothesis of DF test is that\n",
    "there is a unit root in an AR model, which implies\n",
    "that the data series is not stationary.\"\"\"\n",
    "\n",
    "def adf_test(time_series1):\n",
    "    dftest = adfuller(time_series1)\n",
    "    return dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56b0131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pair(pair):\n",
    "    s1 = pair[:pair.find('-')]\n",
    "    s2 = pair[pair.find('-')+1:]\n",
    "    return s1,s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0353c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADF for stationarity\n",
    "results_adf = pd.DataFrame(columns=[\"ADF\"])\n",
    "selected_ticks = []\n",
    "\n",
    "for s1 in returns_form.columns:\n",
    "    if (f'{s1}' not in results_adf.index):\n",
    "        results_adf.loc[f'{s1}'] = adf_test(returns_form[s1])[1]\n",
    "    if adf_test(returns_form[s1])[1]< P_VALUE_THRESHOLD:\n",
    "        selected_ticks.append(f'{s1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f6f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pearson's R\n",
    "selected_pairs = []\n",
    "results = pd.DataFrame(columns=[\"Pearson's R\"])\n",
    "for s1 in selected_ticks:\n",
    "    for s2 in selected_ticks:\n",
    "        if (s1!=s2) and (f'{s2}-{s1}' not in results.index):\n",
    "            results.loc[f'{s1}-{s2}'] = calculate_correlation(returns_form[s1], returns_form[s2])[0]\n",
    "        if calculate_correlation(returns_form[s1], returns_form[s2])[0] > 0.9 and calculate_correlation(returns_form[s1], returns_form[s2])[0] != 1 :\n",
    "            selected_pairs.append(f'{s1}-{s2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629397a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Engle Granger\n",
    "selected_pairs_1 = []\n",
    "#h = []\n",
    "for pair in selected_pairs:\n",
    "    s1, s2 = parse_pair(pair)\n",
    "    interpolated_form_1 = prices_form[s1].interpolate()\n",
    "    interpolated_form_2 = prices_form[s2].interpolate()\n",
    "    if engle_granger_cointegration_test(interpolated_form_1, interpolated_form_2)<P_VALUE_THRESHOLD:\n",
    "            selected_pairs_1.append(f'{s1}-{s2}')\n",
    "            #he = calculate_hurst_of_spread(interpolated_form_1, interpolated_form_2)\n",
    "            #h.append(he)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9057f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Half life\n",
    "selected_pairs_2 = []\n",
    "hl = []\n",
    "for pair in selected_pairs_1:\n",
    "    s1, s2 = parse_pair(pair)\n",
    "    interpolated_form_1 = prices_form[s1].interpolate()\n",
    "    interpolated_form_2 = prices_form[s2].interpolate()\n",
    "    if calculate_half_life(interpolated_form_1, interpolated_form_2) > 1 and calculate_half_life(interpolated_form_1, interpolated_form_2) < 252 :\n",
    "            selected_pairs_2.append(f'{s1}-{s2}')\n",
    "            h = calculate_half_life(interpolated_form_1, interpolated_form_2)\n",
    "            hl.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a5d3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean crosses\n",
    "selected_pairs_3 = []\n",
    "crosses = []\n",
    "for pair in selected_pairs_2:\n",
    "    s1, s2 = parse_pair(pair)\n",
    "    interpolated_form_1 = prices_form[s1].interpolate()\n",
    "    interpolated_form_2 = prices_form[s2].interpolate()\n",
    "    if count_crosses(interpolated_form_1, interpolated_form_2) >= 12:\n",
    "            selected_pairs_3.append(f'{s1}-{s2}')\n",
    "            count = count_crosses(interpolated_form_1, interpolated_form_2)\n",
    "            crosses.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c7a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "array = selected_pairs_3\n",
    "\n",
    "with open('stat_pairs.json', 'w') as f:\n",
    "    json.dump(array, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf2e75b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
